{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier,RidgeClassifier,PassiveAggressiveClassifier\n",
    "import pickle\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas_ml import ConfusionMatrix \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11304, 3)\n"
     ]
    }
   ],
   "source": [
    "input_df = pd.read_csv('incident_1month_resolved.csv')\n",
    "input_df = input_df[(input_df[\"Source\"] == \"Email\")][[\"Subject\",\"Symptom\"]]\n",
    "input_df = input_df.reset_index()\n",
    "print(input_df.shape)\n",
    "# input_df['Symptom'] = input_df['Symptom'].replace(regex='\\n+',value='\\n')\n",
    "# input_df['Symptom'] = input_df['Symptom'].replace(regex='\\r+',value='\\r')\n",
    "# input_df['Symptom'] = input_df['Symptom'].replace(regex='\\+',value='PLUS ')\n",
    "# input_df['Symptom'] = input_df['Symptom'].replace(regex='\\\\|',value=' ORR ')\n",
    "# input_df['Symptom'] = input_df['Symptom'].replace(regex='[\\\\s]+',value=' ')\n",
    "# input_df['Symptom'] = input_df['Symptom'].replace(regex='\\\\-',value='HYP')\n",
    "# input_df['Symptom'] = input_df['Symptom'].replace(regex='\\(',value='OB')\n",
    "# input_df['Symptom'] = input_df['Symptom'].replace(regex='\\)',value='CB')\n",
    "# input_df['Symptom'] = input_df['Symptom'].replace(regex='\\\\-',value='HYP')\n",
    "#print(input_df['Symptom'][4486])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 10\n",
      "0:00:04.944434\n",
      "149 10\n",
      "0:00:05.569962\n",
      "148 10\n",
      "0:00:05.167019\n",
      "147 10\n",
      "0:00:05.104010\n",
      "146 10\n",
      "0:00:05.083989\n",
      "145 10\n",
      "0:00:05.111522\n",
      "144 10\n",
      "0:00:05.297455\n",
      "143 10\n",
      "0:00:05.268952\n",
      "142 10\n",
      "0:00:05.279524\n",
      "141 10\n",
      "0:00:05.663991\n",
      "140 10\n",
      "0:00:05.268437\n",
      "139 10\n",
      "0:00:05.781399\n",
      "138 10\n",
      "0:00:05.793966\n",
      "137 10\n",
      "0:00:06.050921\n",
      "136 10\n",
      "0:00:05.486415\n",
      "135 10\n",
      "0:00:05.599945\n",
      "134 10\n",
      "0:00:05.425435\n",
      "133 10\n",
      "0:00:05.616423\n",
      "132 10\n",
      "0:00:05.857384\n",
      "131 10\n",
      "0:00:05.919503\n",
      "130 10\n",
      "0:00:05.847475\n",
      "129 10\n",
      "0:00:05.873967\n",
      "128 10\n",
      "0:00:06.115482\n",
      "127 10\n",
      "0:00:06.007452\n",
      "126 10\n",
      "0:00:06.058492\n",
      "125 10\n",
      "0:00:06.125939\n",
      "124 10\n",
      "0:00:06.643322\n",
      "123 10\n",
      "0:00:06.480942\n",
      "122 10\n",
      "0:00:06.669937\n",
      "121 10\n",
      "0:00:06.601482\n",
      "120 10\n",
      "0:00:06.980286\n",
      "119 10\n",
      "0:00:07.253948\n",
      "118 10\n",
      "0:00:07.691998\n",
      "117 10\n",
      "0:00:08.406954\n",
      "116 10\n",
      "0:00:07.838395\n",
      "115 10\n",
      "0:00:07.874737\n",
      "114 10\n",
      "0:00:07.680390\n",
      "113 10\n",
      "0:00:08.171871\n",
      "112 10\n",
      "0:00:08.632538\n",
      "111 10\n",
      "0:00:08.711908\n",
      "110 10\n",
      "0:00:09.104378\n",
      "109 10\n",
      "0:00:09.392937\n",
      "108 10\n",
      "0:00:09.070871\n",
      "107 10\n",
      "0:00:09.051931\n",
      "106 10\n",
      "0:00:09.418877\n",
      "105 10\n",
      "0:00:09.849377\n",
      "104 10\n",
      "0:00:10.186366\n",
      "103 10\n",
      "0:00:10.341557\n",
      "102 10\n",
      "0:00:10.859975\n",
      "101 10\n",
      "0:00:11.135653\n",
      "100 10\n",
      "0:00:11.495986\n",
      "99 10\n",
      "0:00:11.723000\n",
      "98 10\n",
      "0:00:11.969575\n",
      "97 10\n",
      "0:00:12.922510\n",
      "96 10\n",
      "0:00:12.868482\n",
      "95 10\n",
      "0:00:13.190505\n",
      "94 10\n",
      "0:00:13.935059\n",
      "93 10\n",
      "0:00:14.024999\n",
      "92 10\n",
      "0:00:14.721526\n",
      "91 10\n",
      "0:00:15.412028\n",
      "90 10\n",
      "0:00:15.810635\n",
      "89 10\n",
      "0:00:16.409087\n",
      "88 10\n",
      "0:00:16.953002\n",
      "87 10\n",
      "0:00:17.807984\n",
      "86 10\n",
      "0:00:18.069510\n",
      "85 10\n",
      "0:00:18.641123\n",
      "84 10\n",
      "0:00:19.150603\n",
      "83 10\n",
      "0:00:19.643905\n",
      "82 10\n",
      "0:00:20.321769\n",
      "81 10\n",
      "0:00:20.988270\n",
      "80 10\n",
      "0:00:21.414189\n",
      "79 10\n",
      "0:00:22.216919\n",
      "78 10\n",
      "0:00:22.965289\n",
      "77 10\n",
      "0:00:23.598283\n",
      "76 10\n",
      "0:00:24.501798\n",
      "75 10\n",
      "0:00:25.164191\n",
      "74 10\n",
      "0:00:25.848685\n",
      "73 10\n",
      "0:00:26.398161\n",
      "72 10\n",
      "0:00:26.936204\n",
      "71 10\n",
      "0:00:27.440467\n",
      "70 10\n",
      "0:00:28.169700\n",
      "69 10\n",
      "0:00:28.857293\n",
      "68 10\n",
      "0:00:29.216662\n",
      "67 10\n",
      "0:00:30.599167\n",
      "66 10\n",
      "0:00:30.600133\n",
      "65 10\n",
      "0:00:30.744654\n",
      "64 10\n",
      "0:00:31.302575\n",
      "63 10\n",
      "0:00:32.150264\n",
      "62 10\n",
      "0:00:32.580699\n",
      "61 10\n",
      "0:00:33.628573\n",
      "60 10\n",
      "0:00:35.170896\n",
      "59 10\n",
      "0:00:39.742647\n",
      "58 10\n",
      "0:00:37.541634\n",
      "57 10\n",
      "0:00:39.966776\n",
      "56 10\n",
      "0:00:39.061926\n",
      "55 10\n",
      "0:00:40.455238\n",
      "54 10\n",
      "0:00:40.234859\n",
      "53 10\n",
      "0:00:43.663371\n",
      "52 10\n",
      "0:00:43.590348\n",
      "51 10\n",
      "0:00:43.817579\n",
      "50 10\n",
      "0:00:48.432978\n",
      "49 10\n",
      "0:00:48.041135\n",
      "48 10\n",
      "0:00:46.487470\n",
      "47 10\n",
      "0:00:47.518004\n",
      "46 10\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "i = 50;\n",
    "input_df[\"New_Symptom\"] = input_df[\"Symptom\"];\n",
    "for i in range(150,10,-1):\n",
    "    for j in range(10,9,-1):\n",
    "        startTime = datetime.now()\n",
    "        print(i , j)\n",
    "        try:\n",
    "            pattern = \"[\\\\S]+\";\n",
    "            tf_vectorizer = CountVectorizer( min_df=j,\n",
    "                                            ngram_range = (i,i),\n",
    "                                            analyzer='word',\n",
    "                                            token_pattern=pattern\n",
    "                                            )\n",
    "            tf_vectorizer.fit(input_df[\"New_Symptom\"])\n",
    "            a =  zip(tf_vectorizer.get_feature_names(), itertools.repeat(\"\"))\n",
    "            new_dict = {re.escape(k): v for k, v in a}\n",
    "            input_df[\"New_Symptom\"].replace(new_dict,regex = True, inplace = True);     \n",
    "            len(tf_vectorizer.vocabulary_)\n",
    "        except ValueError:\n",
    "            print(ValueError)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        print(datetime.now() - startTime)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = \"(?u)[\\\\w.@:-aeiouAEIOU&\\\\r\\\\n\\\\,\\\\-()\\\\']+\";\n",
    "try:\n",
    "    pattern = \"[\\\\S]+\";\n",
    "    tf_vectorizer = CountVectorizer( min_df=10,\n",
    "                                    ngram_range = (98,98),\n",
    "                                    analyzer='word',\n",
    "                                    token_pattern=pattern\n",
    "                                    )\n",
    "    tf_vectorizer.fit(input_df[\"New_Symptom\"])\n",
    "    #tf_vectorizer.vocabulary_ \n",
    "    print(tf_vectorizer.vocabulary_)\n",
    "except ValueError:\n",
    "    print(ValueError)\n",
    "except:\n",
    "    print(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.to_csv(\"kunal1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = input_df['Symptom'].str.lower().str.contains(\"dach & emerging markets maintenance renewals heat software deutschland gmbh gottlieb-manz-strasse 10, 70794 filderstadt, germany p: plus 49 ob0cb711 340190-5406 orr f: plus 49 ob0cb711 340190-5899 valentina.schmidt@heatsoftware.com orr www.heatsoftware.com management board: john ferron, anton kreuzer, jon a. temple. register court: ag - münchen. commercial register number: hrb 13 01 11. value added tax identification number: de 206 863 402. confidentiality note: this email message is for the sole use of the intended recipientobscb and may contain confidential and legally privileged information. any unauthorized review, use, disclosure or distribution is prohibited. if you are not the intended recipient, please contact the sender by reply email and\")\n",
    "a[ a == True ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['Symptom'][4099]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['Symptom'][4099]\n",
    "a = \"dach & emerging markets maintenance renewals heat software deutschland gmbh gottlieb-manz-strasse 10, 70794 filderstadt, germany p: plus 49 ob0cb711 340190-5406 orr f: plus 49 ob0cb711 340190-5899 valentina.schmidt@heatsoftware.com orr www.heatsoftware.com management board: john ferron, anton kreuzer, jon a. temple. register court: ag - münchen. commercial register number: hrb 13 01 11. value added tax identification number: de 206 863 402. confidentiality note: this email message is for the sole use of the intended recipientobscb and may contain confidential and legally privileged information. any unauthorized review, use, disclosure or distribution is prohibited. if you are not the intended recipient, please contact the sender by reply email and\"\n",
    "import re\n",
    " \n",
    "src_str  = re.compile(a, re.IGNORECASE)\n",
    " \n",
    "str_replaced  = src_str.sub(\" \", input_df['Symptom'][4099])\n",
    " \n",
    " \n",
    " \n",
    "print(str_replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,20):\n",
    "    print(repr(input_df['Symptom'][i]))\n",
    "    print(\"\\n-------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['Symptom'] = input_df['Symptom'].replace(regex='(\\r\\n(\\\\s+)?)+',value='\\r\\n ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['Symptom'][1163]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = input_df['Symptom'].str.contains(\"Andy Ng\\r\\n Technical Support \")\n",
    "a[ a == True ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_df['Symptom'] = input_df['Symptom'].replace(regex='(\\r\\n(\\\\s+)?)+',value='\\r\\n ')\n",
    "input_df['Symptom'] = input_df['Symptom'].replace(regex=[\"\\\\sFrom:.*\\\\s\",\n",
    "                        \"\\\\sTo:.*\\\\s\",\"\\\\sDate:.*\\\\s\",\"\\\\sSubject:.*\\\\s\",\"\\\\sSent:.*\\\\s\",\n",
    "                        \"\\\\sCc:.*\\\\s\",\"\\\\sBcc:\\\\s\"], value='')\n",
    "input_df['Symptom'] = input_df['Symptom'].replace(regex=[                                                         \n",
    "                        \"(?s)\\\\sThis message is intended .* destroy all copies\\\\.?\\\\s\",\n",
    "                        \"(?s)\\\\sDisclaimer .* only if necessary\\\\.?\\\\s\",\n",
    "                        \"(?s)\\\\sConfidentiality Note:.*original message\\\\.?\\\\s\"], value='')\n",
    "input_df['Symptom'] = input_df['Symptom'].replace(regex='\\\\s?\\\\(AutoClosed\\\\)', value = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "index = []\n",
    "for i in range(input_df.shape[0]):\n",
    "    if len(input_df['Symptom'][i]) > 3000:\n",
    "        count+=1\n",
    "        index.append(i)\n",
    "#         print(input_df['Symptom'][i])\n",
    "#         print(\"\\n-------------\\n\")\n",
    "\n",
    "print(count)\n",
    "print(index)                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_df['Symptom'][5249])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in range(20):\n",
    "#     print(re.findall(\"\\\\sDiagnostic information for administrators\\\\s\", input_df['Symptom'][i]))\n",
    "# #     print(\"\\n\" + input_df['Subject'][i])\n",
    "#     print(\"\\n-------------\\n\")\n",
    "\n",
    "count = 0\n",
    "index =[]\n",
    "for j in range(input_df.shape[0]):\n",
    "    if len(re.findall(\"o:\", input_df['Symptom'][j])) > 0:\n",
    "        index.append(j)\n",
    "        count+=1\n",
    "        \n",
    "print(count)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"\"\"Good morning,\n",
    " \n",
    " \n",
    " \n",
    "Can you please contact me as soon as possible regarding this issue?\n",
    " \n",
    "Attached is the screen Michal gets when he boots his PC\n",
    " \n",
    "He is just back from holiday and nothing was done to the machine as far as we can tell\n",
    " \n",
    " \n",
    " \n",
    "Thank you for your help,\n",
    " \n",
    "Benjamin Elzingre\n",
    "Technical Support Manager – EMEA\n",
    "Ivanti\n",
    "benjamin.elzingre@ivanti.com | www.heatsoftware.com | www.ivanti.com (AutoClosed)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "b = email.message_from_string(message)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import talon\n",
    "from talon import quotations\n",
    "talon.init()\n",
    "from talon import signature\n",
    "from talon.signature.bruteforce import extract_signature\n",
    "\n",
    "kunal =  input_df['Symptom'].apply(lambda x : extract_signature(x) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kunal[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0;\n",
    "for i in kunal :\n",
    "    if i[1] == None :\n",
    "        a += 1;\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "tagged = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "person = []\n",
    "for subtree in tagged.subtrees(filter=lambda t: t.label() == 'PERSON'):\n",
    "        for leaf in subtree.leaves():\n",
    "            person.append(leaf[0])\n",
    "            \n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dill.source import getsource\n",
    "print(getsource(signature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
